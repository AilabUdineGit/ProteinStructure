{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f9a0624c-c004-4d49-a8b5-d1ace9430821",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/HDD/bportelli/env/lib/python3.8/site-packages/transformers/models/t5/tokenization_t5_fast.py:156: FutureWarning: This tokenizer was incorrectly instantiated with a model max length of 512 which will be corrected in Transformers v5.\n",
      "For now, this behavior is kept to avoid breaking backwards compatibility when padding/encoding with `truncation is True`.\n",
      "- Be aware that you SHOULD NOT rely on t5-small automatically truncating your input to 512 when padding/encoding.\n",
      "- If you want to encode/pad to sequences longer than 512 you can either instantiate this tokenizer with `model_max_length` or pass `max_length` when encoding/padding.\n",
      "- To avoid this warning, please instantiate this tokenizer with `model_max_length` set to your preferred value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Seq</th>\n",
       "      <th>target</th>\n",
       "      <th>x</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BBBBBBBBAAADGDDSL</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt;pad&gt; &lt;pad&gt; &lt;pad&gt; &lt;pad&gt; &lt;pad&gt; &lt;pad&gt; &lt;pad&gt; &lt;pad...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BBBBBBBAAADGDDSLY</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt;pad&gt; &lt;pad&gt; &lt;pad&gt; &lt;pad&gt; &lt;pad&gt; &lt;pad&gt; &lt;pad&gt; A A ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BBBBBBAAADGDDSLYP</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt;pad&gt; &lt;pad&gt; &lt;pad&gt; &lt;pad&gt; &lt;pad&gt; &lt;pad&gt; A A A D G ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BBBBBAAADGDDSLYPI</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt;pad&gt; &lt;pad&gt; &lt;pad&gt; &lt;pad&gt; &lt;pad&gt; A A A D G D D S ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BBBBAAADGDDSLYPIA</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt;pad&gt; &lt;pad&gt; &lt;pad&gt; &lt;pad&gt; A A A D G D D S L Y P I A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>GLTRPKYSLTLTDYDGS</td>\n",
       "      <td>2</td>\n",
       "      <td>G L T R P K Y S L T L T D Y D G S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>LTRPKYSLTLTDYDGSN</td>\n",
       "      <td>2</td>\n",
       "      <td>L T R P K Y S L T L T D Y D G S N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>TRPKYSLTLTDYDGSNN</td>\n",
       "      <td>2</td>\n",
       "      <td>T R P K Y S L T L T D Y D G S N N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>RPKYSLTLTDYDGSNNF</td>\n",
       "      <td>2</td>\n",
       "      <td>R P K Y S L T L T D Y D G S N N F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>PKYSLTLTDYDGSNNFN</td>\n",
       "      <td>2</td>\n",
       "      <td>P K Y S L T L T D Y D G S N N F N</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Seq  target  \\\n",
       "0    BBBBBBBBAAADGDDSL       1   \n",
       "1    BBBBBBBAAADGDDSLY       1   \n",
       "2    BBBBBBAAADGDDSLYP       1   \n",
       "3    BBBBBAAADGDDSLYPI       1   \n",
       "4    BBBBAAADGDDSLYPIA       1   \n",
       "..                 ...     ...   \n",
       "995  GLTRPKYSLTLTDYDGS       2   \n",
       "996  LTRPKYSLTLTDYDGSN       2   \n",
       "997  TRPKYSLTLTDYDGSNN       2   \n",
       "998  RPKYSLTLTDYDGSNNF       2   \n",
       "999  PKYSLTLTDYDGSNNFN       2   \n",
       "\n",
       "                                                     x  \n",
       "0    <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad...  \n",
       "1    <pad> <pad> <pad> <pad> <pad> <pad> <pad> A A ...  \n",
       "2    <pad> <pad> <pad> <pad> <pad> <pad> A A A D G ...  \n",
       "3    <pad> <pad> <pad> <pad> <pad> A A A D G D D S ...  \n",
       "4    <pad> <pad> <pad> <pad> A A A D G D D S L Y P I A  \n",
       "..                                                 ...  \n",
       "995                  G L T R P K Y S L T L T D Y D G S  \n",
       "996                  L T R P K Y S L T L T D Y D G S N  \n",
       "997                  T R P K Y S L T L T D Y D G S N N  \n",
       "998                  R P K Y S L T L T D Y D G S N N F  \n",
       "999                  P K Y S L T L T D Y D G S N N F N  \n",
       "\n",
       "[1000 rows x 3 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import json\n",
    "\n",
    "\n",
    "def batchify(l, batch_size):\n",
    "    i = 0\n",
    "    while i < len(l):\n",
    "        i += batch_size\n",
    "        yield l[i-batch_size:i]\n",
    "\n",
    "\n",
    "test_data = pd.read_csv(\"Bert_Model/new_17resid_test_data.txt\", encoding='unicode_escape', names=['Seq'])\n",
    "test_target = pd.read_csv(\"Bert_Model/Ntest_3states_target.txt\", encoding='unicode_escape', names=['target'])\n",
    "\n",
    "\n",
    "from transformers import AutoTokenizer, T5ForConditionalGeneration\n",
    "model = T5ForConditionalGeneration.from_pretrained(\"t5-small\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"t5-small\")\n",
    "\n",
    "\n",
    "df_ = pd.concat([test_data, test_target], axis=1).head(1000)\n",
    "df_[\"x\"] = df_.Seq.apply(lambda val: \" \".join([x.replace(\"B\", tokenizer.pad_token) for x in val]))\n",
    "df_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a68b1bd2-220a-4d03-9cad-fea8008a24c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer.bos_token = tokenizer.eos_token\n",
    "# tokenizer.bos_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6fca8c6d-7eb5-48b8-b53c-8915021c88d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from captum.attr import DeepLift\n",
    "\n",
    "device = \"cuda\"\n",
    "\n",
    "\n",
    "class BertModelWrapper(nn.Module):\n",
    "\n",
    "    def __init__(self, model):\n",
    "        super(BertModelWrapper, self).__init__()\n",
    "        self.model = model\n",
    "\n",
    "    def forward(self, embeddings, attention_mask=None, head_mask=None, position=0):\n",
    "        model_class = type(self.model)\n",
    "        outputs = self.model.generate(\n",
    "            inputs_embeds = embeddings,\n",
    "            return_dict_in_generate=True,\n",
    "            output_scores=True,\n",
    "            max_new_tokens=1,\n",
    "            # attention_mask = attention_mask, \n",
    "            # head_mask = head_mask,\n",
    "        )\n",
    "        outputs = outputs.scores\n",
    "      \n",
    "        return outputs[0]  # .argmax(1)\n",
    "\n",
    "def interpret_sentence(model_wrapper, sentence, label=1, position=0, plot=True, max_len=None):\n",
    "    model_wrapper.eval()\n",
    "    model_wrapper.zero_grad()\n",
    "    max_len = model_wrapper.model.config.max_position_embeddings if max_len is None else max_len\n",
    "\n",
    "    tok_out = tokenizer(sentence, add_special_tokens=False, padding=\"longest\")#\"max_length\", max_length=max_len)\n",
    "    \n",
    "    tok_out = [\n",
    "        [x for x in seq if (x != 3) and (x != 0)]\n",
    "        for seq in tok_out.input_ids\n",
    "    ]\n",
    "    tok_out = [\n",
    "        seq + [tokenizer.pad_token_id]*(max_len-len(seq))\n",
    "        for seq in tok_out\n",
    "    ]\n",
    "    \n",
    "    for x,s in zip(tok_out, sentence):\n",
    "        if len(x)!=17:\n",
    "            print(len(x), x, s)\n",
    "    \n",
    "    input_ids = torch.tensor(tok_out)\n",
    "    baseline_input_ids = torch.ones_like(input_ids) * tokenizer.pad_token_id\n",
    "\n",
    "    attention_mask = torch.ones_like(input_ids)\n",
    "    \n",
    "    input_ids=input_ids.to(device)\n",
    "    baseline_input_ids=baseline_input_ids.to(device)\n",
    "    \n",
    "    input_embedding = model_wrapper.model.shared(input_ids)\n",
    "    baseline_input_embedding = model_wrapper.model.shared(baseline_input_ids)\n",
    "\n",
    "    # predict\n",
    "    pred = model_wrapper(input_embedding)  # .item()\n",
    "    \n",
    "    # print(pred)\n",
    "    \n",
    "    \n",
    "    # print(input_embedding)\n",
    "    # print(baseline_input_embedding)\n",
    "    \n",
    "    \n",
    "    # print(model_wrapper(baseline_input_embedding))\n",
    "    \n",
    "    # pred_ind = pred.argmax().item()  # round(pred)\n",
    "    \n",
    "    # compute attributions and approximation delta using integrated gradients\n",
    "    # if CAPTUM_ALG == IntegratedGradients:\n",
    "    #     attributions_ig, delta = ig.attribute(input_embedding, n_steps=2, target=label)\n",
    "    # elif CAPTUM_ALG == Saliency or CAPTUM_ALG == FeatureAblation or CAPTUM_ALG == DeepLift:\n",
    "    #     attributions_ig = ig.attribute(\n",
    "    #         input_embedding,\n",
    "    #         target=label,\n",
    "    #         baselines=baseline_input_embedding,\n",
    "    #         additional_forward_args=(None, None, position)\n",
    "    #     )\n",
    "    attributions_ig = dl.attribute(\n",
    "            input_embedding,\n",
    "            target=label,\n",
    "            baselines=baseline_input_embedding,\n",
    "            additional_forward_args=(None, None, position)\n",
    "    )\n",
    "\n",
    "    tokens = tokenizer.convert_ids_to_tokens(input_ids[0].detach().cpu().numpy().tolist())\n",
    "\n",
    "    attributions = attributions_ig.sum(dim=-1).squeeze(0)\n",
    "    attributions = attributions / torch.norm(attributions, dim=-1).unsqueeze(-1)\n",
    "    if len(attributions.shape) == 1:\n",
    "        attributions = attributions.unsqueeze(0)\n",
    "    attributions = attributions.detach().cpu().numpy()\n",
    "    # attributions = np.mean(attributions, axis=0)\n",
    "    attributions = np.mean(np.absolute(attributions), axis=0)\n",
    "\n",
    "    if plot:\n",
    "        visualize_importances(tokens, attributions, log=False)\n",
    "    # return tokens, attributions, pred, pred_ind, label\n",
    "    return attributions\n",
    "\n",
    "def visualize_importances(feature_names, importances, title=\"Average Feature Importances\", plot=True,\n",
    "                          axis_title=\"Features\", log=False):\n",
    "    print(title)\n",
    "    x_pos = [x for x in range(len(feature_names))]\n",
    "    if plot:\n",
    "        # plt.figure(figsize=(6, 4))\n",
    "        plt.plot(x_pos, importances)\n",
    "        # plt.bar(x_pos, importances, align='center')\n",
    "        #         plt.xticks(x_pos, feature_names, wrap=True)\n",
    "        plt.xlabel(axis_title)\n",
    "        if log:\n",
    "            plt.yscale('log')\n",
    "        plt.title(title)\n",
    "        plt.tight_layout()\n",
    "        # plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5e98c978-cfc8-4523-b29f-7e10abd61e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_model_wrapper = BertModelWrapper(model)\n",
    "dl = DeepLift(bert_model_wrapper)\n",
    "_ = bert_model_wrapper.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "87ce27b6-e55c-4521-be0d-24c3f295a4f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6it [00:00,  8.56it/s]                                                                                                  \n",
      "3it [00:00,  9.84it/s]                                                                                                  \n",
      "2it [00:00, 11.95it/s]                                                                                                  \n"
     ]
    }
   ],
   "source": [
    "sent_0 = df_.x[df_.target==0].tolist()\n",
    "attrib_0 = []\n",
    "for sent_batch in tqdm(batchify(sent_0, 100), total=len(sent_0)//100):\n",
    "    attrib = interpret_sentence(\n",
    "        bert_model_wrapper,\n",
    "        sentence=sent_batch,\n",
    "        label=1,\n",
    "        max_len=17,\n",
    "        position=8,\n",
    "        plot=False\n",
    "    )\n",
    "    attrib_0.append(attrib[:17])\n",
    "sent_1 = df_.x[df_.target==1].tolist()\n",
    "attrib_1 = []\n",
    "for sent_batch in tqdm(batchify(sent_1, 100), total=len(sent_1)//100):\n",
    "    attrib = interpret_sentence(\n",
    "        bert_model_wrapper,\n",
    "        sentence=sent_batch,\n",
    "        label=1,\n",
    "        max_len=17,\n",
    "        position=8,\n",
    "        plot=False\n",
    "    )\n",
    "    attrib_1.append(attrib[:17])\n",
    "    \n",
    "sent_2 = df_.x[df_.target==2].tolist()\n",
    "attrib_2 = []\n",
    "for sent_batch in tqdm(batchify(sent_2, 100), total=len(sent_2)//100):\n",
    "    attrib = interpret_sentence(\n",
    "        bert_model_wrapper,\n",
    "        sentence=sent_batch,\n",
    "        label=2,\n",
    "        max_len=17,\n",
    "        position=8,\n",
    "        plot=False\n",
    "    )\n",
    "    attrib_2.append(attrib[:17])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c5ffe9d-14f3-4624-8246-7ed69b2c9302",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0ff037eb-61b4-4b34-aed0-cf7e857549d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_0 = np.mean(attrib_0, axis=0)\n",
    "avg_1 = np.mean(attrib_1, axis=0)\n",
    "avg_2 = np.mean(attrib_2, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "71664e68-0fba-4cd0-9b45-4ec2ff03bc48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.21275407, 0.18024166, 0.18390311, 0.18745466, 0.18280984,\n",
       "       0.17774367, 0.1760658 , 0.1756329 , 0.17240149, 0.17264968,\n",
       "       0.1655397 , 0.16987173, 0.17530452, 0.1841032 , 0.20267248,\n",
       "       0.2090099 , 0.24785304], dtype=float32)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1bd1cafa-0a08-4c0d-b469-efe89d2966ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x216 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "LABELS = [\"-\"+str(x) for x in range(8,0,-1)]+[str(0)]+[str(x) for x in range(1,9,1)]\n",
    "\n",
    "def get_sign_color(w0, pos=\"steelblue\", neg=\"black\"):\n",
    "    return [neg if x<0 else pos for x in w0]\n",
    "\n",
    "\n",
    "abs_avg_w0 = abs(avg_0)\n",
    "abs_avg_w1 = abs(avg_1)\n",
    "abs_avg_w2 = abs(avg_2)\n",
    "\n",
    "fig, axs = plt.subplots(1,3, figsize=(12,3), sharey=True)\n",
    "for i,ax in enumerate(axs):\n",
    "    ax.yaxis.tick_right()\n",
    "    ax.set_xticks(range(len(abs_avg_w0)))\n",
    "    ax.set_xticklabels(LABELS)\n",
    "    if i == 2:\n",
    "        ax.yaxis.set_tick_params(labelright=True, labelleft=False)\n",
    "    else:\n",
    "        for label in ax.get_yticklabels():\n",
    "            label.set_visible(False)\n",
    "axs[0].bar(range(17), abs_avg_w0, color=get_sign_color(avg_0), width=.9)\n",
    "axs[1].bar(range(17), abs_avg_w1, color=get_sign_color(avg_1), width=.9)\n",
    "axs[2].bar(range(17), abs_avg_w2, color=get_sign_color(avg_2), width=.9)\n",
    "axs[0].set_title(f\"Helix Neuron\")\n",
    "axs[1].set_title(f\"Strand Neuron\")\n",
    "axs[2].set_title(f\"Coil Neuron\")\n",
    "\n",
    "plt.tight_layout()\n",
    "fig.subplots_adjust(hspace=0.1, wspace=0)\n",
    "# plt.savefig(f\"BERT_Model.deeplift.avg.pdf\", dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f627e55-66c7-40cf-acda-d9182789062a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
