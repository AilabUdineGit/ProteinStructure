{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f9a0624c-c004-4d49-a8b5-d1ace9430821",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/HDD/bportelli/env/lib/python3.8/site-packages/transformers/models/t5/tokenization_t5_fast.py:156: FutureWarning: This tokenizer was incorrectly instantiated with a model max length of 512 which will be corrected in Transformers v5.\n",
      "For now, this behavior is kept to avoid breaking backwards compatibility when padding/encoding with `truncation is True`.\n",
      "- Be aware that you SHOULD NOT rely on t5-small automatically truncating your input to 512 when padding/encoding.\n",
      "- If you want to encode/pad to sequences longer than 512 you can either instantiate this tokenizer with `model_max_length` or pass `max_length` when encoding/padding.\n",
      "- To avoid this warning, please instantiate this tokenizer with `model_max_length` set to your preferred value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Seq</th>\n",
       "      <th>target</th>\n",
       "      <th>x</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BBBBBBBBAAADGDDSL</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt;pad&gt; &lt;pad&gt; &lt;pad&gt; &lt;pad&gt; &lt;pad&gt; &lt;pad&gt; &lt;pad&gt; &lt;pad...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BBBBBBBAAADGDDSLY</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt;pad&gt; &lt;pad&gt; &lt;pad&gt; &lt;pad&gt; &lt;pad&gt; &lt;pad&gt; &lt;pad&gt; A A ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BBBBBBAAADGDDSLYP</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt;pad&gt; &lt;pad&gt; &lt;pad&gt; &lt;pad&gt; &lt;pad&gt; &lt;pad&gt; A A A D G ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BBBBBAAADGDDSLYPI</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt;pad&gt; &lt;pad&gt; &lt;pad&gt; &lt;pad&gt; &lt;pad&gt; A A A D G D D S ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BBBBAAADGDDSLYPIA</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt;pad&gt; &lt;pad&gt; &lt;pad&gt; &lt;pad&gt; A A A D G D D S L Y P I A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>GLTRPKYSLTLTDYDGS</td>\n",
       "      <td>2</td>\n",
       "      <td>G L T R P K Y S L T L T D Y D G S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>LTRPKYSLTLTDYDGSN</td>\n",
       "      <td>2</td>\n",
       "      <td>L T R P K Y S L T L T D Y D G S N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>TRPKYSLTLTDYDGSNN</td>\n",
       "      <td>2</td>\n",
       "      <td>T R P K Y S L T L T D Y D G S N N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>RPKYSLTLTDYDGSNNF</td>\n",
       "      <td>2</td>\n",
       "      <td>R P K Y S L T L T D Y D G S N N F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>PKYSLTLTDYDGSNNFN</td>\n",
       "      <td>2</td>\n",
       "      <td>P K Y S L T L T D Y D G S N N F N</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Seq  target  \\\n",
       "0    BBBBBBBBAAADGDDSL       1   \n",
       "1    BBBBBBBAAADGDDSLY       1   \n",
       "2    BBBBBBAAADGDDSLYP       1   \n",
       "3    BBBBBAAADGDDSLYPI       1   \n",
       "4    BBBBAAADGDDSLYPIA       1   \n",
       "..                 ...     ...   \n",
       "995  GLTRPKYSLTLTDYDGS       2   \n",
       "996  LTRPKYSLTLTDYDGSN       2   \n",
       "997  TRPKYSLTLTDYDGSNN       2   \n",
       "998  RPKYSLTLTDYDGSNNF       2   \n",
       "999  PKYSLTLTDYDGSNNFN       2   \n",
       "\n",
       "                                                     x  \n",
       "0    <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad...  \n",
       "1    <pad> <pad> <pad> <pad> <pad> <pad> <pad> A A ...  \n",
       "2    <pad> <pad> <pad> <pad> <pad> <pad> A A A D G ...  \n",
       "3    <pad> <pad> <pad> <pad> <pad> A A A D G D D S ...  \n",
       "4    <pad> <pad> <pad> <pad> A A A D G D D S L Y P I A  \n",
       "..                                                 ...  \n",
       "995                  G L T R P K Y S L T L T D Y D G S  \n",
       "996                  L T R P K Y S L T L T D Y D G S N  \n",
       "997                  T R P K Y S L T L T D Y D G S N N  \n",
       "998                  R P K Y S L T L T D Y D G S N N F  \n",
       "999                  P K Y S L T L T D Y D G S N N F N  \n",
       "\n",
       "[1000 rows x 3 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import json\n",
    "\n",
    "\n",
    "def batchify(l, batch_size):\n",
    "    i = 0\n",
    "    while i < len(l):\n",
    "        i += batch_size\n",
    "        yield l[i-batch_size:i]\n",
    "\n",
    "\n",
    "test_data = pd.read_csv(\"Bert_Model/new_17resid_test_data.txt\", encoding='unicode_escape', names=['Seq'])\n",
    "test_target = pd.read_csv(\"Bert_Model/Ntest_3states_target.txt\", encoding='unicode_escape', names=['target'])\n",
    "\n",
    "\n",
    "from transformers import AutoTokenizer, T5ForConditionalGeneration\n",
    "model = T5ForConditionalGeneration.from_pretrained(\"t5-small\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"t5-small\")\n",
    "\n",
    "\n",
    "df_ = pd.concat([test_data, test_target], axis=1).head(1000)\n",
    "df_[\"x\"] = df_.Seq.apply(lambda val: \" \".join([x.replace(\"B\", tokenizer.pad_token) for x in val]))\n",
    "df_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a68b1bd2-220a-4d03-9cad-fea8008a24c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer.bos_token = tokenizer.eos_token\n",
    "# tokenizer.bos_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6fca8c6d-7eb5-48b8-b53c-8915021c88d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from captum.attr import DeepLift\n",
    "\n",
    "device = \"cuda\"\n",
    "\n",
    "# def compute_bert_outputs(model_bert, embedding_output, attention_mask=None, head_mask=None,\n",
    "#                          model_class=BertForTokenClassification):\n",
    "#     if attention_mask is None:\n",
    "#         attention_mask = torch.ones(embedding_output.shape[0], embedding_output.shape[1]).to(embedding_output)\n",
    "\n",
    "#     extended_attention_mask = attention_mask.unsqueeze(1).unsqueeze(2)\n",
    "\n",
    "#     extended_attention_mask = extended_attention_mask.to(\n",
    "#         dtype=next(model_bert.parameters()).dtype)  # fp16 compatibility\n",
    "#     extended_attention_mask = (1.0 - extended_attention_mask) * -10000.0\n",
    "\n",
    "#     if head_mask is not None:\n",
    "#         if head_mask.dim() == 1:\n",
    "#             head_mask = head_mask.unsqueeze(0).unsqueeze(0).unsqueeze(-1).unsqueeze(-1)\n",
    "#             head_mask = head_mask.expand(model_bert.config.num_hidden_layers, -1, -1, -1, -1)\n",
    "#         elif head_mask.dim() == 2:\n",
    "#             head_mask = head_mask.unsqueeze(1).unsqueeze(-1).unsqueeze(-1)  # We can specify head_mask for each layer\n",
    "#         head_mask = head_mask.to(\n",
    "#             dtype=next(model_bert.parameters()).dtype)  # switch to fload if need + fp16 compatibility\n",
    "#     else:\n",
    "#         head_mask = [None] * model_bert.config.num_hidden_layers\n",
    "\n",
    "#     encoder_outputs = model_bert.encoder(embedding_output,\n",
    "#                                          extended_attention_mask,\n",
    "#                                          head_mask=head_mask)\n",
    "\n",
    "#     sequence_output = encoder_outputs[0]\n",
    "\n",
    "#     # if model_class == BertForSequenceClassification:\n",
    "#     #     pooled_output = model_bert.pooler(sequence_output)\n",
    "#     #     outputs = (sequence_output, pooled_output) + encoder_outputs[\n",
    "#     #                                                  1:]  # add hidden_states and attentions if they are here\n",
    "#     #     return outputs  # sequence_output, pooled_output, (hidden_states), (attentions)\n",
    "#     if model_class == BertForTokenClassification:\n",
    "#         outputs = (sequence_output,) + encoder_outputs[1:]  # add hidden_states and attentions if they are here\n",
    "#         return outputs  # sequence_output, pooled_output, (hidden_states), (attentions)\n",
    "\n",
    "\n",
    "class BertModelWrapper(nn.Module):\n",
    "\n",
    "    def __init__(self, model):\n",
    "        super(BertModelWrapper, self).__init__()\n",
    "        self.model = model\n",
    "\n",
    "    def forward(self, embeddings, attention_mask=None, head_mask=None, position=0):\n",
    "        model_class = type(self.model)\n",
    "        outputs = self.model.generate(\n",
    "            inputs_embeds = embeddings,\n",
    "            return_dict_in_generate=True,\n",
    "            output_scores=True,\n",
    "            max_new_tokens=1,\n",
    "            # attention_mask = attention_mask, \n",
    "            # head_mask = head_mask,\n",
    "        )\n",
    "        outputs = outputs.scores\n",
    "        # outputs = compute_bert_outputs(\n",
    "        #     self.model.bert,\n",
    "        #     embeddings,\n",
    "        #     attention_mask=attention_mask,\n",
    "        #     head_mask=head_mask,\n",
    "        #     model_class=model_class\n",
    "        # )\n",
    "        # # if model_class == BertForSequenceClassification:\n",
    "        # #     pooled_output = outputs[1]\n",
    "        # if model_class == BertForTokenClassification:\n",
    "        #     pooled_output = outputs[0]\n",
    "        # pooled_output = self.model.dropout(pooled_output)\n",
    "        # logits = self.model.classifier(pooled_output)\n",
    "        # logits = logits[:, position, :]\n",
    "        # print(outputs[0])\n",
    "        return outputs[0]  # .argmax(1)\n",
    "\n",
    "def interpret_sentence(model_wrapper, sentence, label=1, position=0, plot=True, max_len=None):\n",
    "    model_wrapper.eval()\n",
    "    model_wrapper.zero_grad()\n",
    "    max_len = model_wrapper.model.config.max_position_embeddings if max_len is None else max_len\n",
    "\n",
    "    tok_out = tokenizer(sentence, add_special_tokens=False, padding=\"max_length\", max_length=max_len)\n",
    "    \n",
    "    tok_out = [\n",
    "        [x for x in seq if x != 3]\n",
    "        for seq in tok_out.input_ids\n",
    "    ]\n",
    "    \n",
    "    input_ids = torch.tensor(tok_out)\n",
    "    baseline_input_ids = torch.ones_like(input_ids) * tokenizer.pad_token_id\n",
    "\n",
    "    attention_mask = torch.ones_like(input_ids)\n",
    "    \n",
    "    input_ids=input_ids.to(device)\n",
    "    baseline_input_ids=baseline_input_ids.to(device)\n",
    "    \n",
    "    input_embedding = model_wrapper.model.shared(input_ids)\n",
    "    baseline_input_embedding = model_wrapper.model.shared(baseline_input_ids)\n",
    "\n",
    "    # predict\n",
    "    pred = model_wrapper(input_embedding)  # .item()\n",
    "    \n",
    "    # print(pred)\n",
    "    \n",
    "    \n",
    "    # print(input_embedding)\n",
    "    # print(baseline_input_embedding)\n",
    "    \n",
    "    \n",
    "    # print(model_wrapper(baseline_input_embedding))\n",
    "    \n",
    "    # pred_ind = pred.argmax().item()  # round(pred)\n",
    "    \n",
    "    # compute attributions and approximation delta using integrated gradients\n",
    "    # if CAPTUM_ALG == IntegratedGradients:\n",
    "    #     attributions_ig, delta = ig.attribute(input_embedding, n_steps=2, target=label)\n",
    "    # elif CAPTUM_ALG == Saliency or CAPTUM_ALG == FeatureAblation or CAPTUM_ALG == DeepLift:\n",
    "    #     attributions_ig = ig.attribute(\n",
    "    #         input_embedding,\n",
    "    #         target=label,\n",
    "    #         baselines=baseline_input_embedding,\n",
    "    #         additional_forward_args=(None, None, position)\n",
    "    #     )\n",
    "    attributions_ig = dl.attribute(\n",
    "            input_embedding,\n",
    "            target=label,\n",
    "            baselines=baseline_input_embedding,\n",
    "            additional_forward_args=(None, None, position)\n",
    "    )\n",
    "\n",
    "    tokens = tokenizer.convert_ids_to_tokens(input_ids[0].detach().cpu().numpy().tolist())\n",
    "\n",
    "    attributions = attributions_ig.sum(dim=-1).squeeze(0)\n",
    "    attributions = attributions / torch.norm(attributions, dim=-1).unsqueeze(-1)\n",
    "    if len(attributions.shape) == 1:\n",
    "        attributions = attributions.unsqueeze(0)\n",
    "    attributions = attributions.detach().cpu().numpy()\n",
    "    # attributions = np.mean(attributions, axis=0)\n",
    "    attributions = np.mean(np.absolute(attributions), axis=0)\n",
    "\n",
    "    if plot:\n",
    "        visualize_importances(tokens, attributions, log=False)\n",
    "    # return tokens, attributions, pred, pred_ind, label\n",
    "    return attributions\n",
    "\n",
    "def visualize_importances(feature_names, importances, title=\"Average Feature Importances\", plot=True,\n",
    "                          axis_title=\"Features\", log=False):\n",
    "    print(title)\n",
    "    x_pos = [x for x in range(len(feature_names))]\n",
    "    if plot:\n",
    "        # plt.figure(figsize=(6, 4))\n",
    "        plt.plot(x_pos, importances)\n",
    "        # plt.bar(x_pos, importances, align='center')\n",
    "        #         plt.xticks(x_pos, feature_names, wrap=True)\n",
    "        plt.xlabel(axis_title)\n",
    "        if log:\n",
    "            plt.yscale('log')\n",
    "        plt.title(title)\n",
    "        plt.tight_layout()\n",
    "        # plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5e98c978-cfc8-4523-b29f-7e10abd61e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_model_wrapper = BertModelWrapper(model)\n",
    "dl = DeepLift(bert_model_wrapper)\n",
    "_ = bert_model_wrapper.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "87ce27b6-e55c-4521-be0d-24c3f295a4f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                             | 0/5 [00:00<?, ?it/s]/media/HDD/bportelli/env/lib/python3.8/site-packages/captum/attr/_core/deep_lift.py:336: UserWarning: Setting forward, backward hooks and attributes on non-linear\n",
      "               activations. The hooks and attributes will be removed\n",
      "            after the attribution is finished\n",
      "  warnings.warn(\n",
      "6it [00:00,  9.15it/s]                                                                                                  \n",
      "3it [00:00,  9.95it/s]                                                                                                  \n",
      "2it [00:00, 11.35it/s]                                                                                                  \n"
     ]
    }
   ],
   "source": [
    "sent_0 = df_.x[df_.target==0].tolist()\n",
    "attrib_0 = []\n",
    "for sent_batch in tqdm(batchify(sent_0, 100), total=len(sent_0)//100):\n",
    "    attrib = interpret_sentence(\n",
    "        bert_model_wrapper,\n",
    "        sentence=sent_batch,\n",
    "        label=1,\n",
    "        max_len=17,\n",
    "        position=8,\n",
    "        plot=False\n",
    "    )\n",
    "    attrib_0.append(attrib[:17])\n",
    "sent_1 = df_.x[df_.target==1].tolist()\n",
    "attrib_1 = []\n",
    "for sent_batch in tqdm(batchify(sent_1, 100), total=len(sent_1)//100):\n",
    "    attrib = interpret_sentence(\n",
    "        bert_model_wrapper,\n",
    "        sentence=sent_batch,\n",
    "        label=1,\n",
    "        max_len=17,\n",
    "        position=8,\n",
    "        plot=False\n",
    "    )\n",
    "    attrib_1.append(attrib[:17])\n",
    "    \n",
    "sent_2 = df_.x[df_.target==2].tolist()\n",
    "attrib_2 = []\n",
    "for sent_batch in tqdm(batchify(sent_2, 100), total=len(sent_2)//100):\n",
    "    attrib = interpret_sentence(\n",
    "        bert_model_wrapper,\n",
    "        sentence=sent_batch,\n",
    "        label=2,\n",
    "        max_len=17,\n",
    "        position=8,\n",
    "        plot=False\n",
    "    )\n",
    "    attrib_2.append(attrib[:17])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0ff037eb-61b4-4b34-aed0-cf7e857549d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_0 = np.mean(attrib_0, axis=0)\n",
    "avg_1 = np.mean(attrib_1, axis=0)\n",
    "avg_2 = np.mean(attrib_2, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "71664e68-0fba-4cd0-9b45-4ec2ff03bc48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.21158926, 0.18116002, 0.18377638, 0.18751036, 0.18165076,\n",
       "       0.17680694, 0.17459738, 0.17465319, 0.17191792, 0.17261381,\n",
       "       0.16670473, 0.17140688, 0.17307186, 0.1841551 , 0.20256759,\n",
       "       0.21038468, 0.25074434], dtype=float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1bd1cafa-0a08-4c0d-b469-efe89d2966ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA1gAAADQCAYAAAAalMCAAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAfEklEQVR4nO3de5hddX3v8fenCRcFRTCohXAJihe0ChpCvdRLRQlFiD0Ha7QqtPaxteCptbbiBdQgPV56oa1ooUq9VSLi5cQSCzwivUjRBEUwIDUEJIm0XBVFBALf88da0Z0hM7P3zJpkZs/79Tz7yV6X7/r99sze3+zv+v3WmlQVkiRJkqTJ+6Xt3QFJkiRJGhYWWJIkSZLUEQssSZIkSeqIBZYkSZIkdcQCS5IkSZI6YoElSZIkSR2xwJoFkrwryafa5/sm+UmSOdu7X5KGV5LnJ9mwvfshaftK8mtJru1ZviHJ4duzT9JUs8CaAbaWjJIcn+Q/Bj1WVd1YVbtW1f0T6MclSX6WZJ+edYcnuWHQY0nqVpLnJLk0yY+S3J7ka0kObbdNKF9MpSSV5Kokv9Sz7j1JPrYduyVpFElemWR1e5L2piRfTvKc8eKq6t+r6gl9tvGxNjcs6ln3uCT+0VbNKBZYGtRdwMlT3UiSuVPdhjQskjwc+Gfg74A9gL2BdwP3DHCM7TGqvRewdKobMZ9Ik5PkTcDpwJ8Djwb2BT4ELJmC5m4H3jMFx91CGn4P1pTwjTUkkuyV5HNJbklyfZL/M8p++7dnh+Ym2SPJhiRHt9t2TbI2yWvGaOpvgVckeeyg/WjPTL2nZ3mLKUTtSN1bklwJ3NX28Zgka5L8sB1Be9KI/d+c5Mr2rP1nkuzc9w9NGh6PB6iqc6rq/qq6u6ourKor28/M3wPPbM88/xB+/nn8cJKVSe4CXpDkqCTfSnJnkvVJ3rW5gZ7ccVySG5PcmuTtPdsf0h7zjiRXA4f20e/3A+8erQBK8qvtqNwPk3w7yfN7tm0xsp8tp0Jv7utrk9wIXJzkl5K8I8n3k9yc5BNJduvntUmzWfs5WQacUFWfr6q7quq+qvpSVf1pu89OSU5P8oP2cXqSndptg04X/jjw1CTPG60/ST7ajqJtTDPyPafd9vM80C7//DtPu3xJktOSfA34KXBAkmclWdV+j1iV5Fk98ZckOTXNjIAfJ7kwybzBfoKajSywhkCaMzBfAr5Nc+b6hcAbkxwxVlxV3Q78LvAPSR4F/DVwRVV9YoywjcA/0Jwd76QfI7wCOAp4BHAAcA7wRmBPYCXwpSQ79uz/W8BiYAHwVOD4AdqShsV/Afcn+XiSI5PsvnlDVV0D/AHwn+304Ef0xL0SOA14GPAfNCPUr6H5/B0FvD7JS0e09RzgCTSf71N6Tnq8E3hs+zgCOK6Pfn8euJOtfG6T7A2cT3Mmew/gzcDnkuzZx3E3ex7wpLY/x7ePF9Dkll2BD47Yf7TXJs1mzwR2Br4wxj5vB34VOBh4GrAIeMcE2/spzUjZaaNs/xiwCXgccAjwYuD3Bjj+q4HX0eS9H9Pkmb8FHgn8FXB+kkf27P9K4HeARwE70uQiaUwWWDPHF9uzuD9sz0B/qGfbocCeVbWsqu6tqnU0RdC4U2+q6kLgs8BXgN8Afr+Pvvxf4OgkTx6xfsL96PG3VbW+qu4GXg6cX1UXVdV9wF8ADwGeNWL/H7TF4pdokrs0q1TVnTTFQdF85m5JsiLJo8cJ/X9V9bWqeqCqflZVl1TVVe3ylTQnOEaeRX53O0L2bZqTKU9r1/8WcFpV3V5V62m+sIzbdZopxyePOHEC8CpgZVWtbPtzEbCaJk/1613t2fa7gd8G/qqq1lXVT4C3AktHjJ6N9tqk2eyRwK1VtWmMfX4bWFZVN1fVLTQnYV89iTbPBPZNcmTvyjan/QbwxvazfTPNyeFBvmd8rKrWtK/nxcD3quqTVbWpqs4Bvgsc3bP/P1bVf7V55Fz8nqE+WGDNHC+tqkdsfgB/2LNtP2CvEQXY22jmSffjLOApNEnntvF2bpPnB2mmDPSabD8A1vc83wv4fk+7D7Tb9+7Z5797nv+U5qy0NOtU1TVVdXxVzaf5PO9Fc83EWHo/byQ5LMlX00zx/RHNyNfI6TCjfeb2GnG879OHqloJbODBJ3f2A142Ip88B/jlfo7bGjWftM/nsmV+Mp9ID3YbMG+0qbytrX2+9ppog1V1D3Bq++i1H7ADcFNPXjiTZnSpX2PlBdplv2doUiywhsN64PreAqyqHlZV457pbectnwV8AvjDJI/rs80P0Ey1ecYA/bgLeGjP/o/ZynF77xT0A5pkurmvAfahmaYoaRRV9V2aaTRP2bxqtF1HLH8aWAHsU1W70Vy7lT6bvYnm87nZvn3GQTO96G1smR/WA58ckU92qar3ttsnlU/a/m0C/meAfkqz0X/S3DDnpWPss7XP1w8m2e4/0kxX/l8969a3fZnXkxceXlWbZ9RMNi9A03e/Z2hSLLCGwzeAH6e5QcRDksxJ8pS0t2gex9toks3v0hRNn0gfdxOrqh8Cfwn82QD9uAL4jTQ313gMzbVVYzkXOCrJC5PsAPwJTWK9tI/XJc0aSZ6Y5E+SzG+X96G5nvGydpf/AeZvZRreSA8Dbq+qn6W5TfIrB+jGucBbk+ze9uMN/QZW1SXAd9jyuq1P0UxFPqLNJTu3F8vPb7dfQTPFb4ckC4Fjx2nmHOCPkyxIsivNNR6fGWfakzTrVdWPgFOAM5K8NMlD28/dkUne3+52DvCOJHu2N4E4heYzPJl2N9Fc2/mWnnU3ARcCf5nk4WluXvPYnhtiXAE8N83f/NyNZirwWFYCj09zC/q5SV4OHERzV1ZpwiywhkD7N61eQjMv+HrgVuAjwG5jxSV5BvAm4DXtMd5HU2yd1GfTfwP8/O9p9dGPT9Jc13ADTYL8zDiv61qa6zD+rj3W0cDRVXVvn/2TZosfA4cBX09zR8DLaAqWP2m3XwysAf47ya1jHOcPgWVJfkzzBencAfrwbpqpNdfTfL4/OdAraC6I32PzQnsd1xKak0C30Jy5/lN+8f/WyTQ31LijbfvT4xz/7LZP/9b28WcMUARKs1lV/SXN94V38IvP44nAF9td3kNzjeSVwFXAN+nmVuvn0IyO93oNzc0mrqb5/J9HO3W4vVbzM20/LmecQqm9LOIlNLnyNpqTxi+pqrHypDSuVPm32yRJkiSpC45gSZIkSVJHLLAkSZIkqSMWWJIkSZLUEQssSZIkSerIWH80jnnz5tX++++/jboiaVjccMMNmDskDcrcIWkiLr/88luras/t3Y/Nxiyw9t9/f1avXr2t+iJpSCxcuNDcIWlg5g5JE5Hk+9u7D72cIihJkiRJHbHAkiRJkjTUkixOcm2StUlO2sr2P0hyVZIrkvxHkoN6tr21jbs2yRHjtWWBJUmSJGloJZkDnAEcCRwEvKK3gGp9uqp+paoOBt4P/FUbexCwFHgysBj4UHu8UVlgSZIkSRpmi4C1VbWuqu4FlgNLeneoqjt7FncBqn2+BFheVfdU1fXA2vZ4oxrzJheSJEmSNMPtDazvWd4AHDZypyQnAG8CdgR+vSf2shGxe4/VmCNYkiRJkmayeUlW9zxeN5GDVNUZVfVY4C3AOybaGUewJEnSuI449fyBYy44+agp6IkkPcitVbVwjO0bgX16lue360azHPjwBGMdwZIkSZI01FYBByZZkGRHmptWrOjdIcmBPYtHAd9rn68AlibZKckC4EDgG2M15giWJEmSpKFVVZuSnAhcAMwBzq6qNUmWAauragVwYpLDgfuAO4Dj2tg1Sc4FrgY2ASdU1f1jtWeBJUmSJGmoVdVKYOWIdaf0PP+jMWJPA07rty2nCEqSJElSRyywJEmSJKkjFliSJEmS1BELLEmSJEnqiAWWJEmSJHXEAkuSJEmSOmKBJUmSJEkdscCSJEmSpI5YYEmSJElSRyywJEmSJKkjFliSJEmS1BELLEmSJEnqiAWWJEmSJHXEAkuSJEmSOmKBJUmSJEkdscCSJEmSpI5YYEmSJElSRyywJEmSJA21JIuTXJtkbZKTtrL9TUmuTnJlkq8k2a9n2/1JrmgfK8Zra27XnZckSZKk6SLJHOAM4EXABmBVkhVVdXXPbt8CFlbVT5O8Hng/8PJ2291VdXC/7TmCJUmSJGmYLQLWVtW6qroXWA4s6d2hqr5aVT9tFy8D5k+0MUewpFnmiFPPHzjmgpOPmoKeSNrW/PxLmqX2Btb3LG8ADhtj/9cCX+5Z3jnJamAT8N6q+uJYjVlgSZIkSZrJ5rUF0GZnVdVZEzlQklcBC4Hn9azer6o2JjkAuDjJVVV13WjHsMCSJEmSNJPdWlULx9i+EdinZ3l+u24LSQ4H3g48r6ru2by+qja2/65LcglwCDBqgeU1WJIkSZKG2SrgwCQLkuwILAW2uBtgkkOAM4FjqurmnvW7J9mpfT4PeDbQe3OMB3EES5IkSdLQqqpNSU4ELgDmAGdX1Zoky4DVVbUC+ACwK/DZJAA3VtUxwJOAM5M8QDM49d4Rdx98EAssSZIkSUOtqlYCK0esO6Xn+eGjxF0K/MogbTlFUJIkSZI6YoElSZIkSR2xwJIkSZKkjlhgSZIkSVJHLLAkSZIkqSMWWJIkSZLUEQssSZIkSeqIBZYkSZIkdcQ/NCxJkqRp4YhTzx845oKTj5qCnkgT5wiWJEmSJHXEAkuSJEmSOuIUQUmSJElTYjZO+7TAkiRphpmNX1i07c2099lM66+Gl1MEJUmSJKkjnY9gefZAkiRpdptJ3wcn0lfw+6tG5xRBaQaaSf9xSZIkzSZOEZQkSZKkjlhgSZIkSRpqSRYnuTbJ2iQnbWX7m5JcneTKJF9Jsl/PtuOSfK99HDdeW04RlCRJkibAKfszQ5I5wBnAi4ANwKokK6rq6p7dvgUsrKqfJnk98H7g5Un2AN4JLAQKuLyNvWO09iywpO3IxCxJmmr+XyOxCFhbVesAkiwHlgA/L7Cq6qs9+18GvKp9fgRwUVXd3sZeBCwGzhmtMacISpIkSZrJ5iVZ3fN43YjtewPre5Y3tOtG81rgyxOMdQRLkqTtwVEFSerMrVW1sIsDJXkVzXTA5030GI5gSZIkSRpmG4F9epbnt+u2kORw4O3AMVV1zyCxvRzBkiRJkrYxR7G3qVXAgUkW0BRHS4FX9u6Q5BDgTGBxVd3cs+kC4M+T7N4uvxh461iNWWBJkiRJGlpVtSnJiTTF0hzg7Kpak2QZsLqqVgAfAHYFPpsE4MaqOqaqbk9yKk2RBrBs8w0vRmOBJWla8EyeJElTa6L/1w7D/9FVtRJYOWLdKT3PDx8j9mzg7H7b8hosSZIkSerIrB7BGoZqXJIkSdL04QiWJEmSJHVkKEawHInS9uT7T5IkSZtNmwJrpn1JnWn9lSRJM5ffO7SZ74XpzymCkiRJktSRaTOCNVtM5KwDeOZBkiRJmgkssGYJh5MlSZKkqWeBNYNYJE0dRxY13fkelSRpZrDA0pgmU9Rtj4LQIlSSJEnbkze5kCRJkqSOOIIlSUPOkV1JkrYdCyxNO34Z1DDz/T18/J1KknpZYEma0bzWT5IkTSdegyVJkiRJHXEES9Ks5UiUJEnqmgWWJGlUEy1CLV4lSbOVBZYkSdIAPIEgzTxJFgN/A8wBPlJV7x2x/bnA6cBTgaVVdV7PtvuBq9rFG6vqmLHassCSJEnaBizMpO0jyRzgDOBFwAZgVZIVVXV1z243AscDb97KIe6uqoP7bc8CS5IkSdIwWwSsrap1AEmWA0uAnxdYVXVDu+2ByTZmgSVJmlY8yy9JGtC8JKt7ls+qqrN6lvcG1vcsbwAOG+D4O7fH3wS8t6q+ONbOFliSJEmSZrJbq2rhFB5/v6ramOQA4OIkV1XVdaPtbIElSRoKkxn5ctRMkobaRmCfnuX57bq+VNXG9t91SS4BDgFGLbD8Q8OSJEmShtkq4MAkC5LsCCwFVvQTmGT3JDu1z+cBz6bn2q2tscCSJEmSNLSqahNwInABcA1wblWtSbIsyTEASQ5NsgF4GXBmkjVt+JOA1Um+DXyV5hqsMQsspwhKkiRJGmpVtRJYOWLdKT3PV9FMHRwZdynwK4O05QiWJEmSJHXEESxJkjRjeYMSSdONI1iSJEmS1BELLEmSJEnqiAWWJEmSJHXEAkuSJEmSOmKBJUmSJEkd8S6CkiRp1vHug5KmiiNYkiRJktQRCyxJkiRJ6ogFliRJkiR1xAJLkiRJkjpigSVJkiRJHbHAkiRJkqSOWGBJkiRJUkcssCRJkiSpIxZYkiRJktQRCyxJkiRJQy3J4iTXJlmb5KStbH9ukm8m2ZTk2BHbjkvyvfZx3HhtWWBJkiRJGlpJ5gBnAEcCBwGvSHLQiN1uBI4HPj0idg/gncBhwCLgnUl2H6s9CyxJkiRJw2wRsLaq1lXVvcByYEnvDlV1Q1VdCTwwIvYI4KKqur2q7gAuAhaP1ZgFliRJkqSZbF6S1T2P143Yvjewvmd5Q7uuHwPHzu3zwJIkSZI0Hd1aVQu3dyc2cwRLkiRJ0jDbCOzTszy/XTclsRZYkiRJkobZKuDAJAuS7AgsBVb0GXsB8OIku7c3t3hxu25UFliSJEmShlZVbQJOpCmMrgHOrao1SZYlOQYgyaFJNgAvA85MsqaNvR04laZIWwUsa9eNymuwJEmSJA21qloJrByx7pSe56topv9tLfZs4Ox+23IES5IkSZI6YoElSZIkSR2xwJIkSZKkjlhgSZIkSVJHLLAkSZIkqSMWWJIkSZLUEQssSZIkSeqIBZYkSZIkdcQCS5IkSZI6YoElSZIkSR2xwJIkSZKkjlhgSZIkSVJHLLAkSZIkqSMWWJIkSZLUEQssSZIkSeqIBZYkSZIkdcQCS5IkSZI6YoElSZIkaaglWZzk2iRrk5y0le07JflMu/3rSfZv1++f5O4kV7SPvx+vrblT0H9JkiRJmhaSzAHOAF4EbABWJVlRVVf37PZa4I6qelySpcD7gJe3266rqoP7bc8RLEmSJEnDbBGwtqrWVdW9wHJgyYh9lgAfb5+fB7wwSSbSmAWWJEmSpJlsXpLVPY/Xjdi+N7C+Z3lDu26r+1TVJuBHwCPbbQuSfCvJvyb5tfE64xRBSZIkSTPZrVW1cIqOfROwb1XdluQZwBeTPLmq7hwtwBEsSZIkScNsI7BPz/L8dt1W90kyF9gNuK2q7qmq2wCq6nLgOuDxYzVmgSVJkiRpmK0CDkyyIMmOwFJgxYh9VgDHtc+PBS6uqkqyZ3uTDJIcABwIrBurMacISpIkSRpaVbUpyYnABcAc4OyqWpNkGbC6qlYAHwU+mWQtcDtNEQbwXGBZkvuAB4A/qKrbx2rPAkuSJEnSUKuqlcDKEetO6Xn+M+BlW4n7HPC5QdpyiqAkSZIkdcQCS5IkSZI6YoElSZIkSR2xwJIkSZKkjlhgSZIkSVJHLLAkSZIkqSMWWJIkSZLUEQssSZIkSeqIBZYkSZIkdcQCS5IkSZI6YoElSZIkSR2xwJIkSZKkjlhgSZIkSVJHLLAkSZIkqSMWWJIkSZLUEQssSZIkSeqIBZYkSZIkdcQCS5IkSdJQS7I4ybVJ1iY5aSvbd0rymXb715Ps37Ptre36a5McMV5bFliSJEmShlaSOcAZwJHAQcArkhw0YrfXAndU1eOAvwbe18YeBCwFngwsBj7UHm9UFliSJEmShtkiYG1Vrauqe4HlwJIR+ywBPt4+Pw94YZK065dX1T1VdT2wtj3eqFJVo29MbgG+P6GX8WDzgFu3cexsaXMysbY5PWNnWpsjPR24u2f5lkkce6b9LGZSm5OJnS1tTibWNgdn7ti2sbY5PWNtc3BPAK7tWT6rqs7avJDkWGBxVf1eu/xq4LCqOrFnn++0+2xol68DDgPeBVxWVZ9q138U+HJVnTdaZ+aO1dOq2nOw1za6JKurauG2jJ0tbU4m1janZ+xMa3MqzbSfxUxqczKxs6XNycTa5vY1034Ws6W/s6XNycTa5sznFEFJkiRJw2wjsE/P8vx23Vb3STIX2A24rc/YLVhgSZIkSRpmq4ADkyxIsiPNTStWjNhnBXBc+/xY4OJqrqVaASxt7zK4ADgQ+MZYjY05RbBjZ42/S+exs6XNycTa5vSMnWltTqWZ9rOYSW1OJna2tDmZWNvcvmbaz2K29He2tDmZWNvsWFVtSnIicAEwBzi7qtYkWQasrqoVwEeBTyZZC9xOU4TR7ncucDWwCTihqu4fq70xb3IhSZIkSeqfUwQlSZIkqSMWWJIkSZLUkW1SYCXZLcmXknw7yZokv9Nn3J8muaJ9fCfJ/Un2GKDd57exa5L86wAxP+pp95R+2+s5xqFJNrX33O83ZkmSK9s2Vyd5Tp9xv93GXZXk0iRPG6DNJyb5zyT3JHnzAHGLk1ybZG2SkwaIOzvJze3fGehbkn2SfDXJ1e3v8o8GiN05yTd63nvvHrDtOUm+leSfB4y7of2dXJFk9YCxj0hyXpLvJrkmyTP7iHlCz3v2iiR3JnnjAG3+cfvz+U6Sc5LsPEifp4q5o68Yc8foceaO8WPMHVvGmTvGjxv63NHGTih/zJbc0cZNOH9M19zRmaqa8gfwNuB97fM9aS4c23HAYxxNczePfvd/BM3FaPu2y4/qM+75wD9P4rXOAS4GVgLHDhC3K7+4Ju6pwHf7jHsWsHv7/Ejg6wO0+SjgUOA04M0DvL7rgAOAHYFvAwf1Gftcmj8i+Z0Bf6a/DDy9ff4w4L8GaDPAru3zHYCvA786QNtvAj496HsCuAGYN8H30MeB32uf7wg8YgLvwf8G9utz/72B64GHtMvnAsdPpO9dP8wdfcWZO0aPM3cM/h40d/ziGOaOrccNfe5oYyeUP2Zj7uj5PfWVP6Zz7ujqsa2mCBbwsCSh+UDfTnMXjkG8AjhngP1fCXy+qm4EqKqbB2xvot4AfA4YqL2q+km17zJgF5qfWT9xl1bVHe3iZTT35u+3zZurahVw3wBdXQSsrap1VXUvsBxY0md7/0bzux9IVd1UVd9sn/8YuIbmw9lPbFXVT9rFHdpHXz/bJPOBo4CPDNrniUqyG81/CB8FqKp7q+qHAx7mhcB1VfX9AWLmAg9J83cfHgr8YMA2p4q5YxzmjjHjzB2DMXdsydyx9bihzx1t7ITyxyzNHTB4/piuuaMT26rA+iDwJJof3lXAH1XVA/0GJ3kosJgmgfTr8cDuSS5JcnmS1wwQ+8x2aPfLSZ48QD/3Bn4T+PAAbfXG/2aS7wLnA787gUO8FvjyRNoewN7A+p7lDfT5haULSfYHDqE5I9RvzJwkV9D853NRVfUbezrwZ0Df79UeBVzYvvdeN0DcAuAW4B/bKQIfSbLLgG0vZYAvBVW1EfgL4EbgJuBHVXXhgG1OFXNHf/HmjnGYO/pi7miZO/o29LkDBs8fszB3wAD5Y5rnjk5sqwLrCOAKYC/gYOCDSR4+QPzRwNeqapCzEHOBZ9CcCTgCODnJ4/uI+ybN8ObTgL8DvjhAm6cDbxkkifeqqi9U1ROBlwKnDhKb5AU0ie4tE2l7JkiyK81/dm+sqjv7jauq+6vqYJqzbIuSPKWPtl4C3FxVl0+wu8+pqqfTTJ84Iclz+4ybSzOd4cNVdQhwFzDIfPMdgWOAzw4QszvN2cAFNJ/RXZK8qt/4KWbu6IO5Y2zmjvGZOx7E3DGO2ZA7YGL5YzblDhg8f0zz3NGJKSuwkpyw+aI34ASaYfOqqrU08y6fOF5ckr3a1X1VxSPa/AFwQVXdVVW3Av8GbPVCzBFxu24e2q2qlcAOSeb12eZCYHmSG2j+AvSHkry0n9ie17p5SPuA0dodGZfkqTTDyUuq6rbR2hurzQFsBPbpWZ7frptSSXagSXD/VFWfn8gx2iHvr9KclRzPs4Fj2t/lcuDXk3xqgLY2tv/eDHyBZopDPzYAG3rOdp1Hk/j6dSTwzar6nwFiDgeur6pbquo+4PM0c+y3C3OHuaNL5o6+mTvMHeaOESabP2ZJ7oDB88e0yh1TorbBhV40Q9fvap8/muaD0deFeMBuNPNndxmwzScBX6GpzB8KfAd4Sh9xj+EXF30uohm+zARe88cY7GLTx/W0+/T2ZzRuu8C+wFrgWZP4/byL/i82nQusoznrsPli0ycP0Nb+DH6heoBPAKdP4LXtSXuxJvAQ4N+Blwx4jOczwMWmNHPZH9bz/FJg8QDx/w48oed384EBYpcDvzPg6zsMWNN+TkJzsesbJvp+6vJh7uhrf3PH6DHmjv5jzR2/iDV3jB039LmjjZtQ/phtuaONGSh/TOfc0dVjLtvGqcDHklzV/iDfUs3ZnX78JnBhVd01SINVdU2SfwGupJnL+pGq6uc2nccCr0+yCbgbWFrtu2GK/W/gNUnua9t9eZ/tngI8kuasFcCmqlrYT4NJHgOsBh4OPJDm1poH1RhD4FW1KcmJwAU0d4w5u6rW9NneOTRJY16SDcA7q+qjfYQ+G3g1cFV7xg7gbdWc6RvPLwMfTzKHZsT23Koa6NanE/Bo4Avt72Mu8Omq+pcB4t8A/FM75L4O6Pf2wrsALwJ+f5DOVtXXk5xHM01lE/At4KxBjjGFzB3jM3eMztzRB3PHg5g7xjYbcgdMPH/MmtwBE8sf0zx3dCLb5jMsSZIkScNvW93kQpIkSZKGngWWJEmSJHXEAkuSJEmSOmKBJUmSJEkdscCSJEmSpI5YYEmSJElSRyywJEmSJKkj/x+b8nCHB/DOEAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 864x216 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "LABELS = [\"-\"+str(x) for x in range(8,0,-1)]+[str(0)]+[str(x) for x in range(1,9,1)]\n",
    "\n",
    "def get_sign_color(w0, pos=\"steelblue\", neg=\"black\"):\n",
    "    return [neg if x<0 else pos for x in w0]\n",
    "\n",
    "\n",
    "abs_avg_w0 = abs(avg_0)\n",
    "abs_avg_w1 = abs(avg_1)\n",
    "abs_avg_w2 = abs(avg_2)\n",
    "\n",
    "fig, axs = plt.subplots(1,3, figsize=(12,3), sharey=True)\n",
    "for i,ax in enumerate(axs):\n",
    "    ax.yaxis.tick_right()\n",
    "    ax.set_xticks(range(len(abs_avg_w0)))\n",
    "    ax.set_xticklabels(LABELS)\n",
    "    if i == 2:\n",
    "        ax.yaxis.set_tick_params(labelright=True, labelleft=False)\n",
    "    else:\n",
    "        for label in ax.get_yticklabels():\n",
    "            label.set_visible(False)\n",
    "axs[0].bar(range(17), abs_avg_w0, color=get_sign_color(avg_0), width=.9)\n",
    "axs[1].bar(range(17), abs_avg_w1, color=get_sign_color(avg_1), width=.9)\n",
    "axs[2].bar(range(17), abs_avg_w2, color=get_sign_color(avg_2), width=.9)\n",
    "axs[0].set_title(f\"Helix Neuron\")\n",
    "axs[1].set_title(f\"Strand Neuron\")\n",
    "axs[2].set_title(f\"Coil Neuron\")\n",
    "\n",
    "plt.tight_layout()\n",
    "fig.subplots_adjust(hspace=0.1, wspace=0)\n",
    "# plt.savefig(f\"BERT_Model.deeplift.avg.pdf\", dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f627e55-66c7-40cf-acda-d9182789062a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
