{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f9a0624c-c004-4d49-a8b5-d1ace9430821",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForTokenClassification: ['cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Seq</th>\n",
       "      <th>target</th>\n",
       "      <th>x</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BBBBBBBBAAADGDDSL</td>\n",
       "      <td>1</td>\n",
       "      <td>[PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BBBBBBBAAADGDDSLY</td>\n",
       "      <td>1</td>\n",
       "      <td>[PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] A A ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BBBBBBAAADGDDSLYP</td>\n",
       "      <td>1</td>\n",
       "      <td>[PAD] [PAD] [PAD] [PAD] [PAD] [PAD] A A A D G ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BBBBBAAADGDDSLYPI</td>\n",
       "      <td>1</td>\n",
       "      <td>[PAD] [PAD] [PAD] [PAD] [PAD] A A A D G D D S ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BBBBAAADGDDSLYPIA</td>\n",
       "      <td>1</td>\n",
       "      <td>[PAD] [PAD] [PAD] [PAD] A A A D G D D S L Y P I A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>GLTRPKYSLTLTDYDGS</td>\n",
       "      <td>2</td>\n",
       "      <td>G L T R P K Y S L T L T D Y D G S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>LTRPKYSLTLTDYDGSN</td>\n",
       "      <td>2</td>\n",
       "      <td>L T R P K Y S L T L T D Y D G S N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>TRPKYSLTLTDYDGSNN</td>\n",
       "      <td>2</td>\n",
       "      <td>T R P K Y S L T L T D Y D G S N N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>RPKYSLTLTDYDGSNNF</td>\n",
       "      <td>2</td>\n",
       "      <td>R P K Y S L T L T D Y D G S N N F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>PKYSLTLTDYDGSNNFN</td>\n",
       "      <td>2</td>\n",
       "      <td>P K Y S L T L T D Y D G S N N F N</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Seq  target  \\\n",
       "0    BBBBBBBBAAADGDDSL       1   \n",
       "1    BBBBBBBAAADGDDSLY       1   \n",
       "2    BBBBBBAAADGDDSLYP       1   \n",
       "3    BBBBBAAADGDDSLYPI       1   \n",
       "4    BBBBAAADGDDSLYPIA       1   \n",
       "..                 ...     ...   \n",
       "995  GLTRPKYSLTLTDYDGS       2   \n",
       "996  LTRPKYSLTLTDYDGSN       2   \n",
       "997  TRPKYSLTLTDYDGSNN       2   \n",
       "998  RPKYSLTLTDYDGSNNF       2   \n",
       "999  PKYSLTLTDYDGSNNFN       2   \n",
       "\n",
       "                                                     x  \n",
       "0    [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD...  \n",
       "1    [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] A A ...  \n",
       "2    [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] A A A D G ...  \n",
       "3    [PAD] [PAD] [PAD] [PAD] [PAD] A A A D G D D S ...  \n",
       "4    [PAD] [PAD] [PAD] [PAD] A A A D G D D S L Y P I A  \n",
       "..                                                 ...  \n",
       "995                  G L T R P K Y S L T L T D Y D G S  \n",
       "996                  L T R P K Y S L T L T D Y D G S N  \n",
       "997                  T R P K Y S L T L T D Y D G S N N  \n",
       "998                  R P K Y S L T L T D Y D G S N N F  \n",
       "999                  P K Y S L T L T D Y D G S N N F N  \n",
       "\n",
       "[1000 rows x 3 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import json\n",
    "\n",
    "\n",
    "def batchify(l, batch_size):\n",
    "    i = 0\n",
    "    while i < len(l):\n",
    "        i += batch_size\n",
    "        yield l[i-batch_size:i]\n",
    "\n",
    "\n",
    "test_data = pd.read_csv(\"Bert_Model/new_17resid_test_data.txt\", encoding='unicode_escape', names=['Seq'])\n",
    "test_target = pd.read_csv(\"Bert_Model/Ntest_3states_target.txt\", encoding='unicode_escape', names=['target'])\n",
    "\n",
    "\n",
    "from transformers import BertForTokenClassification, AutoModelForTokenClassification, AutoTokenizer, BertConfig, BertTokenizerFast\n",
    "model = AutoModelForTokenClassification.from_pretrained(\"bert-base-uncased\", num_labels=3)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "\n",
    "df_ = pd.concat([test_data, test_target], axis=1).head(1000)\n",
    "df_[\"x\"] = df_.Seq.apply(lambda val: \" \".join([x.replace(\"B\", \"[PAD]\") for x in val]))\n",
    "df_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5227e50c-083c-4334-a3a0-33a7f66841b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FINETUNED_MODEL_PATH = \"Bert_Model/finetuned_model/maxseq_17_tokencls_lr_1e-06/checkpoint_epoch19\"\n",
    "\n",
    "# config = BertConfig.from_pretrained(FINETUNED_MODEL_PATH)\n",
    "\n",
    "# config.num_labels = 3\n",
    "\n",
    "# MAX_LEN = 17\n",
    "# TRAIN_BATCH_SIZE = 128\n",
    "# VALID_BATCH_SIZE = 128\n",
    "# EPOCHS = 20\n",
    "# LEARNING_RATE = 1e-05\n",
    "# MAX_GRAD_NORM = 10\n",
    "# ADD_SPECIAL_TOKENS = False\n",
    "\n",
    "\n",
    "# def load_json(path):\n",
    "#     with open(path, \"r\") as f:\n",
    "#         data = json.load(f)\n",
    "#     return data\n",
    "\n",
    "\n",
    "# fast_tokenizer_args = load_json(\n",
    "#     \"Bert_Model/pretraining_code/Protein/tokenizer_output_files/BertWordPieceTokenizer/fast_tokenizer_args.json\"\n",
    "# )\n",
    "# tokenizer = BertTokenizerFast.from_pretrained(\n",
    "#     \"Bert_Model/pretraining_code/Protein/tokenizer_output_files/BertWordPieceTokenizer\",\n",
    "#     **fast_tokenizer_args\n",
    "# )\n",
    "# model = BertForTokenClassification.from_pretrained(FINETUNED_MODEL_PATH, config=config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f4da19e8-af2c-4821-8f1d-090ea7d50d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from captum.attr import DeepLift\n",
    "\n",
    "device = \"cuda\"\n",
    "\n",
    "def compute_bert_outputs(model_bert, embedding_output, attention_mask=None, head_mask=None,\n",
    "                         model_class=BertForTokenClassification):\n",
    "    if attention_mask is None:\n",
    "        attention_mask = torch.ones(embedding_output.shape[0], embedding_output.shape[1]).to(embedding_output)\n",
    "\n",
    "    extended_attention_mask = attention_mask.unsqueeze(1).unsqueeze(2)\n",
    "\n",
    "    extended_attention_mask = extended_attention_mask.to(\n",
    "        dtype=next(model_bert.parameters()).dtype)  # fp16 compatibility\n",
    "    extended_attention_mask = (1.0 - extended_attention_mask) * -10000.0\n",
    "\n",
    "    if head_mask is not None:\n",
    "        if head_mask.dim() == 1:\n",
    "            head_mask = head_mask.unsqueeze(0).unsqueeze(0).unsqueeze(-1).unsqueeze(-1)\n",
    "            head_mask = head_mask.expand(model_bert.config.num_hidden_layers, -1, -1, -1, -1)\n",
    "        elif head_mask.dim() == 2:\n",
    "            head_mask = head_mask.unsqueeze(1).unsqueeze(-1).unsqueeze(-1)  # We can specify head_mask for each layer\n",
    "        head_mask = head_mask.to(\n",
    "            dtype=next(model_bert.parameters()).dtype)  # switch to fload if need + fp16 compatibility\n",
    "    else:\n",
    "        head_mask = [None] * model_bert.config.num_hidden_layers\n",
    "\n",
    "    encoder_outputs = model_bert.encoder(embedding_output,\n",
    "                                         extended_attention_mask,\n",
    "                                         head_mask=head_mask)\n",
    "\n",
    "    sequence_output = encoder_outputs[0]\n",
    "\n",
    "    # if model_class == BertForSequenceClassification:\n",
    "    #     pooled_output = model_bert.pooler(sequence_output)\n",
    "    #     outputs = (sequence_output, pooled_output) + encoder_outputs[\n",
    "    #                                                  1:]  # add hidden_states and attentions if they are here\n",
    "    #     return outputs  # sequence_output, pooled_output, (hidden_states), (attentions)\n",
    "    if model_class == BertForTokenClassification:\n",
    "        outputs = (sequence_output,) + encoder_outputs[1:]  # add hidden_states and attentions if they are here\n",
    "        return outputs  # sequence_output, pooled_output, (hidden_states), (attentions)\n",
    "\n",
    "\n",
    "class BertModelWrapper(nn.Module):\n",
    "\n",
    "    def __init__(self, model):\n",
    "        super(BertModelWrapper, self).__init__()\n",
    "        self.model = model\n",
    "\n",
    "    def forward(self, embeddings, attention_mask=None, head_mask=None, position=0):\n",
    "        model_class = type(self.model)\n",
    "        outputs = compute_bert_outputs(\n",
    "            self.model.bert,\n",
    "            embeddings,\n",
    "            attention_mask=attention_mask,\n",
    "            head_mask=head_mask,\n",
    "            model_class=model_class\n",
    "        )\n",
    "        # if model_class == BertForSequenceClassification:\n",
    "        #     pooled_output = outputs[1]\n",
    "        if model_class == BertForTokenClassification:\n",
    "            pooled_output = outputs[0]\n",
    "        pooled_output = self.model.dropout(pooled_output)\n",
    "        logits = self.model.classifier(pooled_output)\n",
    "        logits = logits[:, position, :]\n",
    "        print(logits)\n",
    "        return logits  # .argmax(1)\n",
    "\n",
    "def interpret_sentence(model_wrapper, sentence, label=1, position=0, plot=True, max_len=None):\n",
    "    model_wrapper.eval()\n",
    "    model_wrapper.zero_grad()\n",
    "    max_len = model_wrapper.model.config.max_position_embeddings if max_len is None else max_len\n",
    "\n",
    "    tok_out = tokenizer(sentence, add_special_tokens=False, padding=\"max_length\", max_length=max_len)\n",
    "\n",
    "    input_ids = torch.tensor(tok_out.input_ids)\n",
    "    baseline_input_ids = torch.ones_like(input_ids) * tokenizer.pad_token_id\n",
    "\n",
    "    attention_mask = torch.tensor(tok_out.attention_mask)\n",
    "    \n",
    "    input_ids=input_ids.to(device)\n",
    "    baseline_input_ids=baseline_input_ids.to(device)\n",
    "    \n",
    "    input_embedding = model_wrapper.model.bert.embeddings(input_ids)\n",
    "    baseline_input_embedding = model_wrapper.model.bert.embeddings(baseline_input_ids)\n",
    "\n",
    "    # predict\n",
    "    pred = model_wrapper(input_embedding)  # .item()\n",
    "    \n",
    "    print(pred)\n",
    "    # print(model_wrapper(baseline_input_embedding))\n",
    "    \n",
    "    pred_ind = pred.argmax().item()  # round(pred)\n",
    "    \n",
    "    # compute attributions and approximation delta using integrated gradients\n",
    "    # if CAPTUM_ALG == IntegratedGradients:\n",
    "    #     attributions_ig, delta = ig.attribute(input_embedding, n_steps=2, target=label)\n",
    "    # elif CAPTUM_ALG == Saliency or CAPTUM_ALG == FeatureAblation or CAPTUM_ALG == DeepLift:\n",
    "    #     attributions_ig = ig.attribute(\n",
    "    #         input_embedding,\n",
    "    #         target=label,\n",
    "    #         baselines=baseline_input_embedding,\n",
    "    #         additional_forward_args=(None, None, position)\n",
    "    #     )\n",
    "    attributions_ig = dl.attribute(\n",
    "            input_embedding,\n",
    "            target=label,\n",
    "            baselines=baseline_input_embedding,\n",
    "            additional_forward_args=(None, None, position)\n",
    "    )\n",
    "\n",
    "    tokens = tokenizer.convert_ids_to_tokens(input_ids[0].detach().cpu().numpy().tolist())\n",
    "\n",
    "    attributions = attributions_ig.sum(dim=-1).squeeze(0)\n",
    "    attributions = attributions / torch.norm(attributions, dim=-1).unsqueeze(-1)\n",
    "    if len(attributions.shape) == 1:\n",
    "        attributions = attributions.unsqueeze(0)\n",
    "    attributions = attributions.detach().cpu().numpy()\n",
    "    # attributions = np.mean(attributions, axis=0)\n",
    "    attributions = np.mean(np.absolute(attributions), axis=0)\n",
    "\n",
    "    if plot:\n",
    "        visualize_importances(tokens, attributions, log=False)\n",
    "    # return tokens, attributions, pred, pred_ind, label\n",
    "    return attributions\n",
    "\n",
    "def visualize_importances(feature_names, importances, title=\"Average Feature Importances\", plot=True,\n",
    "                          axis_title=\"Features\", log=False):\n",
    "    print(title)\n",
    "    x_pos = [x for x in range(len(feature_names))]\n",
    "    if plot:\n",
    "        # plt.figure(figsize=(6, 4))\n",
    "        plt.plot(x_pos, importances)\n",
    "        # plt.bar(x_pos, importances, align='center')\n",
    "        #         plt.xticks(x_pos, feature_names, wrap=True)\n",
    "        plt.xlabel(axis_title)\n",
    "        if log:\n",
    "            plt.yscale('log')\n",
    "        plt.title(title)\n",
    "        plt.tight_layout()\n",
    "        # plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "78155473-8f8d-419b-8542-3b2cece16743",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from captum.attr import DeepLift\n",
    "\n",
    "device = \"cuda\"\n",
    "\n",
    "# def compute_bert_outputs(model_bert, embedding_output, attention_mask=None, head_mask=None,\n",
    "#                          model_class=BertForTokenClassification):\n",
    "#     if attention_mask is None:\n",
    "#         attention_mask = torch.ones(embedding_output.shape[0], embedding_output.shape[1]).to(embedding_output)\n",
    "\n",
    "#     extended_attention_mask = attention_mask.unsqueeze(1).unsqueeze(2)\n",
    "\n",
    "#     extended_attention_mask = extended_attention_mask.to(\n",
    "#         dtype=next(model_bert.parameters()).dtype)  # fp16 compatibility\n",
    "#     extended_attention_mask = (1.0 - extended_attention_mask) * -10000.0\n",
    "\n",
    "#     if head_mask is not None:\n",
    "#         if head_mask.dim() == 1:\n",
    "#             head_mask = head_mask.unsqueeze(0).unsqueeze(0).unsqueeze(-1).unsqueeze(-1)\n",
    "#             head_mask = head_mask.expand(model_bert.config.num_hidden_layers, -1, -1, -1, -1)\n",
    "#         elif head_mask.dim() == 2:\n",
    "#             head_mask = head_mask.unsqueeze(1).unsqueeze(-1).unsqueeze(-1)  # We can specify head_mask for each layer\n",
    "#         head_mask = head_mask.to(\n",
    "#             dtype=next(model_bert.parameters()).dtype)  # switch to fload if need + fp16 compatibility\n",
    "#     else:\n",
    "#         head_mask = [None] * model_bert.config.num_hidden_layers\n",
    "\n",
    "#     encoder_outputs = model_bert.encoder(embedding_output,\n",
    "#                                          extended_attention_mask,\n",
    "#                                          head_mask=head_mask)\n",
    "\n",
    "#     sequence_output = encoder_outputs[0]\n",
    "\n",
    "#     # if model_class == BertForSequenceClassification:\n",
    "#     #     pooled_output = model_bert.pooler(sequence_output)\n",
    "#     #     outputs = (sequence_output, pooled_output) + encoder_outputs[\n",
    "#     #                                                  1:]  # add hidden_states and attentions if they are here\n",
    "#     #     return outputs  # sequence_output, pooled_output, (hidden_states), (attentions)\n",
    "#     if model_class == BertForTokenClassification:\n",
    "#         outputs = (sequence_output,) + encoder_outputs[1:]  # add hidden_states and attentions if they are here\n",
    "#         return outputs  # sequence_output, pooled_output, (hidden_states), (attentions)\n",
    "\n",
    "\n",
    "class BertModelWrapper(nn.Module):\n",
    "\n",
    "    def __init__(self, model):\n",
    "        super(BertModelWrapper, self).__init__()\n",
    "        self.model = model\n",
    "\n",
    "    def forward(self, embeddings, attention_mask=None, head_mask=None, position=0):\n",
    "        model_class = type(self.model)\n",
    "        outputs = self.model.bert(\n",
    "            inputs_embeds = embeddings,\n",
    "            attention_mask = attention_mask, \n",
    "            head_mask = head_mask,\n",
    "        )\n",
    "        # outputs = compute_bert_outputs(\n",
    "        #     self.model.bert,\n",
    "        #     embeddings,\n",
    "        #     attention_mask=attention_mask,\n",
    "        #     head_mask=head_mask,\n",
    "        #     model_class=model_class\n",
    "        # )\n",
    "        # # if model_class == BertForSequenceClassification:\n",
    "        # #     pooled_output = outputs[1]\n",
    "        if model_class == BertForTokenClassification:\n",
    "            pooled_output = outputs[0]\n",
    "        pooled_output = self.model.dropout(pooled_output)\n",
    "        logits = self.model.classifier(pooled_output)\n",
    "        logits = logits[:, position, :]\n",
    "        # print(logits)\n",
    "        # assert False\n",
    "        return logits  # .argmax(1)\n",
    "\n",
    "def interpret_sentence(model_wrapper, sentence, label=1, position=0, plot=True, max_len=None):\n",
    "    model_wrapper.eval()\n",
    "    model_wrapper.zero_grad()\n",
    "    max_len = model_wrapper.model.config.max_position_embeddings if max_len is None else max_len\n",
    "\n",
    "    tok_out = tokenizer(sentence, add_special_tokens=False, padding=\"max_length\", max_length=max_len)\n",
    "\n",
    "    input_ids = torch.tensor(tok_out.input_ids)\n",
    "    baseline_input_ids = torch.ones_like(input_ids) * tokenizer.pad_token_id\n",
    "\n",
    "    attention_mask = torch.tensor(tok_out.attention_mask)\n",
    "    \n",
    "    input_ids=input_ids.to(device)\n",
    "    baseline_input_ids=baseline_input_ids.to(device)\n",
    "    \n",
    "    input_embedding = model_wrapper.model.bert.embeddings(input_ids)\n",
    "    baseline_input_embedding = model_wrapper.model.bert.embeddings(baseline_input_ids)\n",
    "\n",
    "    # predict\n",
    "    pred = model_wrapper(input_embedding)  # .item()\n",
    "    \n",
    "    # print(pred)\n",
    "    # print(model_wrapper(baseline_input_embedding))\n",
    "    \n",
    "    pred_ind = pred.argmax().item()  # round(pred)\n",
    "    \n",
    "    # compute attributions and approximation delta using integrated gradients\n",
    "    # if CAPTUM_ALG == IntegratedGradients:\n",
    "    #     attributions_ig, delta = ig.attribute(input_embedding, n_steps=2, target=label)\n",
    "    # elif CAPTUM_ALG == Saliency or CAPTUM_ALG == FeatureAblation or CAPTUM_ALG == DeepLift:\n",
    "    #     attributions_ig = ig.attribute(\n",
    "    #         input_embedding,\n",
    "    #         target=label,\n",
    "    #         baselines=baseline_input_embedding,\n",
    "    #         additional_forward_args=(None, None, position)\n",
    "    #     )\n",
    "    attributions_ig = dl.attribute(\n",
    "            input_embedding,\n",
    "            target=label,\n",
    "            baselines=baseline_input_embedding,\n",
    "            additional_forward_args=(None, None, position)\n",
    "    )\n",
    "\n",
    "    tokens = tokenizer.convert_ids_to_tokens(input_ids[0].detach().cpu().numpy().tolist())\n",
    "\n",
    "    attributions = attributions_ig.sum(dim=-1).squeeze(0)\n",
    "    attributions = attributions / torch.norm(attributions, dim=-1).unsqueeze(-1)\n",
    "    if len(attributions.shape) == 1:\n",
    "        attributions = attributions.unsqueeze(0)\n",
    "    attributions = attributions.detach().cpu().numpy()\n",
    "    # attributions = np.mean(attributions, axis=0)\n",
    "    attributions = np.mean(np.absolute(attributions), axis=0)\n",
    "\n",
    "    if plot:\n",
    "        visualize_importances(tokens, attributions, log=False)\n",
    "    # return tokens, attributions, pred, pred_ind, label\n",
    "    return attributions\n",
    "\n",
    "def visualize_importances(feature_names, importances, title=\"Average Feature Importances\", plot=True,\n",
    "                          axis_title=\"Features\", log=False):\n",
    "    print(title)\n",
    "    x_pos = [x for x in range(len(feature_names))]\n",
    "    if plot:\n",
    "        # plt.figure(figsize=(6, 4))\n",
    "        plt.plot(x_pos, importances)\n",
    "        # plt.bar(x_pos, importances, align='center')\n",
    "        #         plt.xticks(x_pos, feature_names, wrap=True)\n",
    "        plt.xlabel(axis_title)\n",
    "        if log:\n",
    "            plt.yscale('log')\n",
    "        plt.title(title)\n",
    "        plt.tight_layout()\n",
    "        # plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5e98c978-cfc8-4523-b29f-7e10abd61e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_model_wrapper = BertModelWrapper(model)\n",
    "dl = DeepLift(bert_model_wrapper)\n",
    "_=bert_model_wrapper.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "87ce27b6-e55c-4521-be0d-24c3f295a4f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6it [00:01,  4.43it/s]                                                                                                  \n",
      "3it [00:00,  4.79it/s]                                                                                                  \n",
      "2it [00:00,  7.15it/s]                                                                                                  \n"
     ]
    }
   ],
   "source": [
    "sent_0 = df_.x[df_.target==0].tolist()\n",
    "attrib_0 = []\n",
    "for sent_batch in tqdm(batchify(sent_0, 100), total=len(sent_0)//100):\n",
    "    attrib = interpret_sentence(\n",
    "        bert_model_wrapper,\n",
    "        sentence=sent_batch,\n",
    "        label=0,\n",
    "        max_len=17,\n",
    "        position=8,\n",
    "        plot=False\n",
    "    )\n",
    "    attrib_0.append(attrib)\n",
    "sent_1 = df_.x[df_.target==1].tolist()\n",
    "attrib_1 = []\n",
    "for sent_batch in tqdm(batchify(sent_1, 100), total=len(sent_1)//100):\n",
    "    attrib = interpret_sentence(\n",
    "        bert_model_wrapper,\n",
    "        sentence=sent_batch,\n",
    "        label=1,\n",
    "        max_len=17,\n",
    "        position=8,\n",
    "        plot=False\n",
    "    )\n",
    "    attrib_1.append(attrib)\n",
    "    \n",
    "sent_2 = df_.x[df_.target==2].tolist()\n",
    "attrib_2 = []\n",
    "for sent_batch in tqdm(batchify(sent_2, 100), total=len(sent_2)//100):\n",
    "    attrib = interpret_sentence(\n",
    "        bert_model_wrapper,\n",
    "        sentence=sent_batch,\n",
    "        label=2,\n",
    "        max_len=17,\n",
    "        position=8,\n",
    "        plot=False\n",
    "    )\n",
    "    attrib_2.append(attrib)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0ff037eb-61b4-4b34-aed0-cf7e857549d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_0 = np.mean(attrib_0, axis=0)\n",
    "avg_1 = np.mean(attrib_1, axis=0)\n",
    "avg_2 = np.mean(attrib_2, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1bd1cafa-0a08-4c0d-b469-efe89d2966ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x216 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "LABELS = [\"-\"+str(x) for x in range(8,0,-1)]+[str(0)]+[str(x) for x in range(1,9,1)]\n",
    "\n",
    "def get_sign_color(w0, pos=\"steelblue\", neg=\"black\"):\n",
    "    return [neg if x<0 else pos for x in w0]\n",
    "\n",
    "\n",
    "abs_avg_w0 = abs(avg_0)\n",
    "abs_avg_w1 = abs(avg_1)\n",
    "abs_avg_w2 = abs(avg_2)\n",
    "\n",
    "fig, axs = plt.subplots(1,3, figsize=(12,3), sharey=True)\n",
    "for i,ax in enumerate(axs):\n",
    "    ax.yaxis.tick_right()\n",
    "    ax.set_xticks(range(len(abs_avg_w0)))\n",
    "    ax.set_xticklabels(LABELS)\n",
    "    if i == 2:\n",
    "        ax.yaxis.set_tick_params(labelright=True, labelleft=False)\n",
    "    else:\n",
    "        for label in ax.get_yticklabels():\n",
    "            label.set_visible(False)\n",
    "axs[0].bar(range(17), abs_avg_w0, color=get_sign_color(avg_0), width=.9)\n",
    "axs[1].bar(range(17), abs_avg_w1, color=get_sign_color(avg_1), width=.9)\n",
    "axs[2].bar(range(17), abs_avg_w2, color=get_sign_color(avg_2), width=.9)\n",
    "axs[0].set_title(f\"Helix Neuron\")\n",
    "axs[1].set_title(f\"Strand Neuron\")\n",
    "axs[2].set_title(f\"Coil Neuron\")\n",
    "\n",
    "plt.tight_layout()\n",
    "fig.subplots_adjust(hspace=0.1, wspace=0)\n",
    "# plt.savefig(f\"BERT_Model.deeplift.avg.pdf\", dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f627e55-66c7-40cf-acda-d9182789062a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
